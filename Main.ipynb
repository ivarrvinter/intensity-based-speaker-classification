{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gf4peqVVujD"
      },
      "source": [
        "# Speaker Classification through Intensity-based Rhythms "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhqGGo_8XZNq"
      },
      "source": [
        "#### Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Odi9q7eEh22q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "#import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yky8O28qh9ro"
      },
      "source": [
        "#### Reading the dataframe and selecting the features and target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t_WbKcfeh9XC"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('intensity.csv')\n",
        "\n",
        "X = df[['rPVIm', 'nPVIm', 'rPVIp', 'nPVIp']]\n",
        "y = df['speaker']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcT_RiEpiLcU"
      },
      "source": [
        "#### Splitting data into training sets and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8IGGKBsCicaS"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=49)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPzJbmi6ie3L"
      },
      "source": [
        "#### Creating the pipeline for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fzwcTqRaiiZb"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('selector', SelectKBest(f_classif, k=4)),\n",
        "    ('logreg', LogisticRegression(C=14.0, penalty='l2', solver='saga', max_iter=900))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpkhrVSUijkD"
      },
      "source": [
        "#### Training the model and predicting the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7Wr_Xv3sixCt"
      },
      "outputs": [],
      "source": [
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKU1H2-XiytK"
      },
      "source": [
        "#### Generating a classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJ1VwjXTi3Dw"
      },
      "outputs": [],
      "source": [
        "report = classification_report(y_test, y_pred, zero_division=1)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2pT9a4ei5AM"
      },
      "source": [
        "#### Joblib draft for future maintenance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhBVh43CjBwj"
      },
      "outputs": [],
      "source": [
        "#joblib.dump(pipeline, 'intensity-pipeline.joblib')\n",
        "#joblib.load('intensity-pipeline.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLkgIJInj-wR"
      },
      "source": [
        "### Fine-tuning with hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-_XpwoqEkHg3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('intensity.csv')\n",
        "\n",
        "X = df[['rPVIm', 'nPVIm', 'rPVIp', 'nPVIp']]\n",
        "y = df['speaker']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=49)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "param_grid = {\n",
        "    'C': np.linspace(0.001, 20.0, 40),\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['saga']\n",
        "}\n",
        "\n",
        "model = LogisticRegression(random_state=49, max_iter=10000)\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "report = classification_report(y_test, y_pred, zero_division=1)\n",
        "print(report)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}