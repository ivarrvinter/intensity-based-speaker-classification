{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Speaker Classification through Intensity-based Rhythms "
      ],
      "metadata": {
        "id": "5gf4peqVVujD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Flowchart"
      ],
      "metadata": {
        "id": "fQEY9tVzmJY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "+-----------------------+\n",
        "|       Load Data        |\n",
        "|           |           |\n",
        "|           V           |\n",
        "| +-------------------+ |\n",
        "| |     intensity.csv  | |\n",
        "| +-------------------+ |\n",
        "+-----------------------+\n",
        "              |\n",
        "              V\n",
        "+-----------------------+\n",
        "|    Split Data into     |\n",
        "|   Training and Test   |\n",
        "|           |           |\n",
        "|           V           |\n",
        "| +-------------------+ |\n",
        "| |     train_test     | |\n",
        "| |      _split       | |\n",
        "| +-------------------+ |\n",
        "+-----------------------+\n",
        "              |\n",
        "              V\n",
        "+------------------------+\n",
        "|    Feature Engineering  |\n",
        "|            |           |\n",
        "|            V           |\n",
        "| +-------------------+ |\n",
        "| |   SelectKBest     | |\n",
        "| |     f_classif     | |\n",
        "| +-------------------+ |\n",
        "|            |           |\n",
        "|            V           |\n",
        "| +-------------------+ |\n",
        "| |    Standardize    | |\n",
        "| +-------------------+ |\n",
        "+-----------------------+\n",
        "              |\n",
        "              V\n",
        "+------------------------+\n",
        "|  Train Logistic        |\n",
        "|   Regression Model     |\n",
        "|            |           |\n",
        "|            V           |\n",
        "| +-------------------+ |\n",
        "| |    Logistic       | |\n",
        "| |   Regression      | |\n",
        "| +-------------------+ |\n",
        "|            |           |\n",
        "|            V           |\n",
        "| +-------------------+ |\n",
        "| |   Trained Model   | |\n",
        "| +-------------------+ |\n",
        "+-----------------------+\n",
        "              |\n",
        "              V\n",
        "+------------------------+\n",
        "|     Evaluate Model     |\n",
        "|            |           |\n",
        "|            V           |\n",
        "| +-------------------+ |\n",
        "| | classification    | |\n",
        "| |     report        | |\n",
        "| +-------------------+ |\n",
        "|            |           |\n",
        "|            V           |\n",
        "| +-------------------+ |\n",
        "| |  Precision, Recall| |\n",
        "| |      F1-score    | |\n",
        "| +-------------------+ |\n",
        "+-----------------------+"
      ],
      "metadata": {
        "id": "IaBXDWwFmUTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing libraries"
      ],
      "metadata": {
        "id": "dhqGGo_8XZNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "#import joblib"
      ],
      "metadata": {
        "id": "Odi9q7eEh22q"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reading the dataframe and selecting the features and target"
      ],
      "metadata": {
        "id": "yky8O28qh9ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('intensity.csv')\n",
        "\n",
        "X = df[['rPVIm', 'nPVIm', 'rPVIp', 'nPVIp']]\n",
        "y = df['speaker']"
      ],
      "metadata": {
        "id": "t_WbKcfeh9XC"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Splitting data into training sets and testing sets"
      ],
      "metadata": {
        "id": "wcT_RiEpiLcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=49)"
      ],
      "metadata": {
        "id": "8IGGKBsCicaS"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating the pipeline for the model"
      ],
      "metadata": {
        "id": "OPzJbmi6ie3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('selector', SelectKBest(f_classif, k=4)),\n",
        "    ('logreg', LogisticRegression(C=14.0, penalty='l2', solver='saga', max_iter=900))\n",
        "])"
      ],
      "metadata": {
        "id": "fzwcTqRaiiZb"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training the model and predicting the training set"
      ],
      "metadata": {
        "id": "FpkhrVSUijkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)"
      ],
      "metadata": {
        "id": "7Wr_Xv3sixCt"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generating a classification report"
      ],
      "metadata": {
        "id": "gKU1H2-XiytK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(y_test, y_pred, zero_division=1)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ1VwjXTi3Dw",
        "outputId": "6171f88e-3333-48f8-e71b-40c2a898c478"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.27      0.28      0.27        25\n",
            "           2       0.06      0.06      0.06        18\n",
            "           3       0.15      0.38      0.22        16\n",
            "           4       0.00      0.00      0.00        18\n",
            "           5       0.17      0.05      0.07        22\n",
            "           6       0.10      0.20      0.13        15\n",
            "           7       0.00      0.00      0.00        25\n",
            "           8       0.21      0.16      0.18        25\n",
            "           9       0.48      0.67      0.56        21\n",
            "          10       0.18      0.12      0.15        16\n",
            "          11       0.17      0.10      0.12        21\n",
            "          12       0.25      0.10      0.14        21\n",
            "          13       0.45      0.20      0.28        25\n",
            "          14       0.21      0.55      0.31        22\n",
            "          15       0.00      0.00      0.00        22\n",
            "          16       0.05      0.05      0.05        20\n",
            "          17       0.76      0.93      0.84        28\n",
            "          18       0.07      0.11      0.09        18\n",
            "          19       0.59      0.65      0.62        20\n",
            "          20       0.29      0.24      0.26        17\n",
            "          21       0.20      0.79      0.32        19\n",
            "          22       1.00      0.00      0.00        31\n",
            "          23       0.35      0.39      0.37        28\n",
            "          24       1.00      0.00      0.00        26\n",
            "\n",
            "    accuracy                           0.25       519\n",
            "   macro avg       0.29      0.25      0.21       519\n",
            "weighted avg       0.33      0.25      0.22       519\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Joblib draft for future maintenance"
      ],
      "metadata": {
        "id": "I2pT9a4ei5AM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#joblib.dump(pipeline, 'intensity-pipeline.joblib')\n",
        "#joblib.load('intensity-pipeline.joblib')"
      ],
      "metadata": {
        "id": "qhBVh43CjBwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Knowledge graph visualization"
      ],
      "metadata": {
        "id": "9HbRHIgul5na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from graphviz import Digraph\n",
        "\n",
        "dot = Digraph()\n",
        "\n",
        "dot.node(\"Load Data\", shape=\"rectangle\", style=\"filled\", fillcolor=\"#FFCCCC\")\n",
        "dot.node(\"Split Data\", shape=\"rectangle\", style=\"filled\", fillcolor=\"#CCCCFF\")\n",
        "dot.node(\"Feature Engineering\", shape=\"rectangle\", style=\"filled\", fillcolor=\"#CCFFCC\")\n",
        "dot.node(\"Train Model\", shape=\"rectangle\", style=\"filled\", fillcolor=\"#99FF99\")\n",
        "dot.node(\"Evaluate Model\", shape=\"rectangle\", style=\"filled\", fillcolor=\"#CC99FF\")\n",
        "dot.node(\"X, y\", shape=\"oval\", style=\"filled\", fillcolor=\"#FFFFCC\")\n",
        "dot.node(\"Classification Report\", shape=\"oval\", style=\"filled\", fillcolor=\"#FFFFCC\")\n",
        "\n",
        "dot.edge(\"Load Data\", \"Split Data\")\n",
        "dot.edge(\"Split Data\", \"Feature Engineering\")\n",
        "dot.edge(\"Feature Engineering\", \"Train Model\")\n",
        "dot.edge(\"Train Model\", \"Evaluate Model\")\n",
        "dot.edge(\"Split Data\", \"X, y\")\n",
        "dot.edge(\"Evaluate Model\", \"Classification Report\")\n",
        "\n",
        "dot.render(\"knowledge_graph.gv\", view=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Em90YOewl-qJ",
        "outputId": "1004dc13-20b0-4e5d-811f-cebbe4460794"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'knowledge_graph.gv.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tuning with hyperparameters"
      ],
      "metadata": {
        "id": "qLkgIJInj-wR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('intensity.csv')\n",
        "\n",
        "X = df[['rPVIm', 'nPVIm', 'rPVIp', 'nPVIp']]\n",
        "y = df['speaker']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=49)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "param_grid = {\n",
        "    'C': np.linspace(0.001, 20.0, 40),\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['saga']\n",
        "}\n",
        "\n",
        "model = LogisticRegression(random_state=49, max_iter=10000)\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "report = classification_report(y_test, y_pred, zero_division=1)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "-_XpwoqEkHg3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}